{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_caic_weather_data(url):\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    all_data = []\n",
    "    current_zone = None\n",
    "\n",
    "    # Find all table elements\n",
    "    tables = soup.find_all('table', class_='sortable')\n",
    "\n",
    "    for table in tables:\n",
    "        # Extract the zone name from the preceding h4 element\n",
    "        zone_header = table.find_previous('h4')\n",
    "        if zone_header:\n",
    "            current_zone = zone_header.text.strip()\n",
    "\n",
    "        # Extract column headers\n",
    "        headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "        # Extract rows\n",
    "        rows = table.find_all('tr')[1:]  # Skip the header row\n",
    "\n",
    "        # Process each row\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= len(headers):\n",
    "                data = {headers[i]: cols[i].text.strip() for i in range(len(headers))}\n",
    "                data['Zone'] = current_zone\n",
    "                all_data.append(data)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# URL of the CAIC weather stations page\n",
    "url = \"https://classic.avalanche.state.co.us/caic/obs_stns/zones.php\"\n",
    "\n",
    "# Scrape the data\n",
    "try:\n",
    "    weather_data = scrape_caic_weather_data(url)\n",
    "    \n",
    "    # Save to CSV\n",
    "    weather_data.to_csv(\"caic_weather_data.csv\", index=False)\n",
    "    print(\"Data has been scraped and saved to 'caic_weather_data.csv'\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst few rows of the scraped data:\")\n",
    "    print(weather_data.head())\n",
    "    \n",
    "    # Display summary information\n",
    "    print(\"\\nDataset summary:\")\n",
    "    print(weather_data.info())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while scraping the data: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
